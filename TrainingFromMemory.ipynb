{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70213e54-12fc-44c5-ad80-c6c7d021a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65e9c45c-adbd-4b4e-8b04-785d760bc89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local path variables\n",
    "from datapath import data_path, zip_path\n",
    "\n",
    "# Colab path variables\n",
    "#zip_path = \"sample_data/dogs-vs-cats.zip\"\n",
    "#data_path = \"sample_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61af39f-c045-4fe4-91ef-706505490eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the image directories from the zip files\n",
    "zip_outer = zipfile.ZipFile(zip_path,'r')\n",
    "zip_outer.extractall(data_path)\n",
    "zip_outer.close()\n",
    "\n",
    "zip_train = zipfile.ZipFile(zip_train_path)\n",
    "zip_train.extractall(data_path)\n",
    "zip_train.close()\n",
    "\n",
    "zip_test = zipfile.ZipFile(zip_test_path)\n",
    "zip_test.extractall(data_path)\n",
    "zip_test.close()\n",
    "\n",
    "del zip_outer, zip_train, zip_test\n",
    "\n",
    "# delete zip files to reclaim space\n",
    "os.remove(f\"{data_path}/train.zip\")\n",
    "os.remove(f\"{data_path}/test1.zip\")\n",
    "# os.remove(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28973fe3-524b-4419-99b5-049b88ea7131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_image(source,destination,image_name):\n",
    "     shutil.move(os.path.join(source,image_name),\n",
    "                 os.path.join(destination,image_name),\n",
    "                 copy_function=copyfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c199c3-c5de-456a-93ef-0bd13fd4a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_images(source_path,cat_path,dog_path,index_limit):\n",
    "    for index,fname in enumerate(os.listdir(source_path)):\n",
    "        if index < index_limit:\n",
    "            move_image(source_path,cat_path,fname)\n",
    "        else:\n",
    "            move_image(source_path,dog_path,fname)\n",
    "    \n",
    "    shutil.rmtree(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c48768d9-f8d9-49f0-8ef1-dcaf35bc3e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dogs vs cats dataset, reshape and save to a new file\n",
    "\n",
    "def load_images(image_dir, target_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for file in os.listdir(image_dir):\n",
    "        image_label = 0\n",
    "        if file.startswith('cat'):\n",
    "            image_label = 1\n",
    "        image = img_to_array(\n",
    "            load_img(os.path.join(image_dir,file),target_size=target_size))\n",
    "        images.append(image)\n",
    "        labels.append(image_label)\n",
    "    \n",
    "    images = np.asarray(images)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ccc305f-d304-4909-abbe-6c14c4ebbb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = load_images(os.path.join(data_path,'train'),(200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85548763-ba36-4694-b4c1-653b8974b57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 200, 200, 3), (25000,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd901f6e-cebd-4690-9b59-99ef846858d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras model for image classification\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Alternating convolution and pooling layers to process the images before analysis\n",
    "    # The convulation layers accent features from the images,\n",
    "    # The pooling layers reduce the amount of information to process\n",
    "    tf.keras.layers.Conv2D(32,(3,3), activation='relu', input_shape=(200,200,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the images for analysis by the nn\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Neural network for image classification 256 neuron hidden layer, with a 1 nueron output layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation ='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04ea4a3c-9050-450a-b0dd-d406d5951a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 664s 847ms/step - loss: 0.8594 - acc: 0.6613\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 658s 842ms/step - loss: 0.4963 - acc: 0.7650\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(test_images,test_labels, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d2770-247e-4f23-b33f-30b5c0158fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
